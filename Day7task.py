import json
from langchain.document_loaders import UnstructuredFileLoader
from langchain.text_splitter import CharacterTextSplitter
from langchain.chat_models import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.callbacks import StreamingStdOutCallbackHandler
from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser
import streamlit as st
from langchain.retrievers import WikipediaRetriever
from langchain.schema import SystemMessage
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain.document_loaders.sitemap import SitemapLoader
from langchain.text_splitter import CharacterTextSplitter

s# ê° í”„ë¡œë•íŠ¸ ê³µì‹ë¬¸ì„œ ë©”ì¸ URL (ì„¤ëª…, ìš©ë„ í‘œì‹œ)
AI_GATEWAY_URL = "https://developers.cloudflare.com/ai-gateway/"
VECTORIZER_URL = "https://developers.cloudflare.com/vectorize/"
WORKERS_AI_URL = "https://developers.cloudflare.com/workers-ai/"
SITEMAP_URL = "https://developers.cloudflare.com/sitemap-0.xml"

with st.sidebar:
    st.title("â˜ï¸ SiteGPT - Cloudflare Docs Chatbot")
    openai_api_key = st.text_input("Enter your OpenAI API Key:", type="password")
    st.markdown("[ğŸ”— GitHub Repo](https://github.com/yourusername/sideGPT-cloudflare)")

    # ê³µì‹ë¬¸ì„œ ë¹ ë¥¸ ë§í¬
    st.markdown("**Docs Quick Links**")
    st.markdown(f"- [AI Gateway]({AI_GATEWAY_URL})")
    st.markdown(f"- [Vectorize]({VECTORIZER_URL})")
    st.markdown(f"- [Workers AI]({WORKERS_AI_URL})")

st.title("ğŸ’¬ Cloudflare Docs Chatbot")
st.caption("AI Gateway / Vectorize / Workers AI ê³µì‹ ë¬¸ì„œ ê¸°ë°˜ Q&A")

if not openai_api_key:
    st.warning("Please enter your OpenAI API Key to continue.")
    st.stop()

if "messages" not in st.session_state:
    st.session_state.messages = []

@st.cache_resource(show_spinner="ë¬¸ì„œ ì„ë² ë”© ë° ì¸ë±ì‹± ì¤‘...")
def get_retriever(api_key):
    # í•˜ë‚˜ì˜ ì‚¬ì´íŠ¸ë§µì—ì„œ ì „ì²´ ë¬¸ì„œ ìˆ˜ì§‘
    loader = SitemapLoader(web_path=SITEMAP_URL)
    all_docs = loader.load()
    # í•„ìš”ì‹œ ì•„ë˜ì²˜ëŸ¼ ì œí’ˆë³„ë¡œ í•„í„°ë§ ê°€ëŠ¥ (ì°¸ê³ ìš©, ì§€ê¸ˆì€ ì „ì²´ ë¬¸ì„œ ì‚¬ìš©)
    # all_docs = [doc for doc in all_docs if any(
    #     x in doc.metadata['source'] for x in [AI_GATEWAY_URL, VECTORIZER_URL, WORKERS_AI_URL]
    # )]
    splitter = CharacterTextSplitter.from_tiktoken_encoder(chunk_size=700, chunk_overlap=100)
    split_docs = splitter.split_documents(all_docs)
    embeddings = OpenAIEmbeddings(openai_api_key=api_key)
    vectordb = FAISS.from_documents(split_docs, embeddings)
    return vectordb.as_retriever()

retriever = get_retriever(openai_api_key)
llm = ChatOpenAI(model="gpt-4", temperature=0, openai_api_key=openai_api_key)
qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)

for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

if prompt := st.chat_input("Cloudflare ê³µì‹ë¬¸ì„œì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³´ì„¸ìš”!"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
    with st.chat_message("assistant"):
        with st.spinner("Cloudflare ê³µì‹ë¬¸ì„œë¥¼ ê²€ìƒ‰ ì¤‘..."):
            answer = qa_chain.run(prompt)
            st.markdown(answer)
            st.session_state.messages.append({"role": "assistant", "content": answer})